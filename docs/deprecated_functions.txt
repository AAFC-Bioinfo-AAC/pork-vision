def execute_color_standardization(image, reference_path):
    reference_image = cv2.imread(reference_path)
    #reference_image = white_balance(reference_image, "SimpleWB")

    #balance = white_balance(image, "SimpleWB")
    standardized_image = LAB_check(reference_image, image)
    return standardized_image

def reference_standardize(image, reference_image):
    '''
    Takes in a list of images, and a reference.
    Standardizes the list of images to the reference
    by matching histograms.
    Returns standardized image.
    '''
    def match_channel(source, target):
        # Calculate the mean and standard deviation of source and target channels
        mean_source, std_source = cv2.meanStdDev(source)
        mean_target, std_target = cv2.meanStdDev(target)
    
        # Normalize the source channel
        normalized_source = (source - mean_source) / std_source
        matched_channel = (normalized_source * std_target) + mean_target
    
        # Clip the values to be in valid LAB range [0, 255]
        matched_channel = np.clip(matched_channel, 0, 255).astype(np.uint8)
        return matched_channel
    lab_source = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    lab_target = cv2.cvtColor(reference_image, cv2.COLOR_BGR2LAB)

    L_source, A_source, B_source = cv2.split(lab_source)
    L_target, A_target, B_target = cv2.split(lab_target)
    L_matched = match_channel(L_source, L_target)
    A_matched = match_channel(A_source, A_target)
    B_matched = match_channel(B_source, B_target)
    lab_matched = cv2.merge([L_matched, A_matched, B_matched])
    standard_img = cv2.cvtColor(lab_matched, cv2.COLOR_LAB2BGR)

    #standard_img = match_histograms(image, reference_image, channel_axis=-1)
    #standard_img = cv2.medianBlur(standard_img, 3) #Used just to approximate Category cutoffs
    return standard_img

def LAB_check(reference_image, image):
    lab_ref = cv2.cvtColor(reference_image, cv2.COLOR_BGR2LAB)
    lab_current = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l_ref, a_ref, b_ref = cv2.split(lab_ref)
    l_cur, a_cur, b_cur = cv2.split(lab_current)
    if (np.mean(l_cur)/np.mean(l_ref) < 0.99) or (np.mean(l_cur)/np.mean(l_ref) > 1.01) \
    or (np.mean(a_cur)/np.mean(a_ref) < 0.99) or (np.mean(a_cur)/np.mean(a_ref) > 1.01) \
    or (np.mean(b_cur)/np.mean(b_ref) < 0.99) or (np.mean(b_cur)/np.mean(b_ref) > 1.01):
        #print("Outside margin of error, add to correction list")
        standard_img  = reference_standardize(image, reference_image)
        return standard_img
    else:
        #print("Within margin of error, no need to standardize")
        return image

def white_balance(image, option):
    '''
    Balance the white in an image
    Helps reduce lighting impact.
    Simple WB: Result is closer to the original, but increased variance.
    Learning WB: Result has less variance.
    '''
    if option == "SimpleWB":
        result = cv2.xphoto.createSimpleWB().balanceWhite(image)
    if option == "LearnWB":
        result = cv2.xphoto.createLearningBasedWB().balanceWhite(image)
    return result

##############MARBLING###################

def clean_specks(marbling_mask):
    """
    Removes noisy speckles of detected fat from the image
    Ensures only significant areas remain.
    """
    kernel = np.ones((100, 100), np.uint8)    
    marbling_mask = cv2.morphologyEx(marbling_mask, cv2.MORPH_OPEN, kernel, iterations=20)
    return marbling_mask

def convert_fat_color(image):
    """ Converts white pixels in the overlay to yellow for fat regions. """
    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    white_mask = (lab_image[:, :, 0] == 255) & (lab_image[:, :, 1] == 128) & (lab_image[:, :, 2] == 128)
    lab_image[white_mask, 2] = lab_image[white_mask, 2] + 100
    lab_image = np.clip(lab_image, 0, 255)
    return cv2.cvtColor(lab_image.astype(np.uint8), cv2.COLOR_LAB2BGR)