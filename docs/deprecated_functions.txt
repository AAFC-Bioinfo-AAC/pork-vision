def execute_color_standardization(image, reference_path):
    reference_image = cv2.imread(reference_path)
    #reference_image = white_balance(reference_image, "SimpleWB")

    #balance = white_balance(image, "SimpleWB")
    standardized_image = LAB_check(reference_image, image)
    return standardized_image

def reference_standardize(image, reference_image):
    '''
    Takes in a list of images, and a reference.
    Standardizes the list of images to the reference
    by matching histograms.
    Returns standardized image.
    '''
    def match_channel(source, target):
        # Calculate the mean and standard deviation of source and target channels
        mean_source, std_source = cv2.meanStdDev(source)
        mean_target, std_target = cv2.meanStdDev(target)
    
        # Normalize the source channel
        normalized_source = (source - mean_source) / std_source
        matched_channel = (normalized_source * std_target) + mean_target
    
        # Clip the values to be in valid LAB range [0, 255]
        matched_channel = np.clip(matched_channel, 0, 255).astype(np.uint8)
        return matched_channel
    lab_source = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    lab_target = cv2.cvtColor(reference_image, cv2.COLOR_BGR2LAB)

    L_source, A_source, B_source = cv2.split(lab_source)
    L_target, A_target, B_target = cv2.split(lab_target)
    L_matched = match_channel(L_source, L_target)
    A_matched = match_channel(A_source, A_target)
    B_matched = match_channel(B_source, B_target)
    lab_matched = cv2.merge([L_matched, A_matched, B_matched])
    standard_img = cv2.cvtColor(lab_matched, cv2.COLOR_LAB2BGR)

    #standard_img = match_histograms(image, reference_image, channel_axis=-1)
    #standard_img = cv2.medianBlur(standard_img, 3) #Used just to approximate Category cutoffs
    return standard_img

def LAB_check(reference_image, image):
    lab_ref = cv2.cvtColor(reference_image, cv2.COLOR_BGR2LAB)
    lab_current = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l_ref, a_ref, b_ref = cv2.split(lab_ref)
    l_cur, a_cur, b_cur = cv2.split(lab_current)
    if (np.mean(l_cur)/np.mean(l_ref) < 0.99) or (np.mean(l_cur)/np.mean(l_ref) > 1.01) \
    or (np.mean(a_cur)/np.mean(a_ref) < 0.99) or (np.mean(a_cur)/np.mean(a_ref) > 1.01) \
    or (np.mean(b_cur)/np.mean(b_ref) < 0.99) or (np.mean(b_cur)/np.mean(b_ref) > 1.01):
        #print("Outside margin of error, add to correction list")
        standard_img  = reference_standardize(image, reference_image)
        return standard_img
    else:
        #print("Within margin of error, no need to standardize")
        return image

def white_balance(image, option):
    '''
    Balance the white in an image
    Helps reduce lighting impact.
    Simple WB: Result is closer to the original, but increased variance.
    Learning WB: Result has less variance.
    '''
    if option == "SimpleWB":
        result = cv2.xphoto.createSimpleWB().balanceWhite(image)
    if option == "LearnWB":
        result = cv2.xphoto.createLearningBasedWB().balanceWhite(image)
    return result

##############MARBLING###################

def clean_specks(marbling_mask):
    """
    Removes noisy speckles of detected fat from the image
    Ensures only significant areas remain.
    """
    kernel = np.ones((100, 100), np.uint8)    
    marbling_mask = cv2.morphologyEx(marbling_mask, cv2.MORPH_OPEN, kernel, iterations=20)
    return marbling_mask

def convert_fat_color(image):
    """ Converts white pixels in the overlay to yellow for fat regions. """
    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    white_mask = (lab_image[:, :, 0] == 255) & (lab_image[:, :, 1] == 128) & (lab_image[:, :, 2] == 128)
    lab_image[white_mask, 2] = lab_image[white_mask, 2] + 100
    lab_image = np.clip(lab_image, 0, 255)
    return cv2.cvtColor(lab_image.astype(np.uint8), cv2.COLOR_LAB2BGR)


# ROTATION
def dilate_mask(binary_mask, kernel_size=15):
    """
    Dilates the given binary mask to create a 'band' around the object.

    Parameters:
    - binary_mask (np.ndarray): A binary (0/255) mask.
    - kernel_size (int): Size of the dilation kernel.

    Returns:
    - np.ndarray: Dilated mask.
    """
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    return cv2.dilate(binary_mask, kernel, iterations=1)

def find_largest_contour(mask, min_area=500):
    """
    Finds the largest contour in a binary mask, ignoring contours smaller than min_area.

    Parameters:
    - mask (np.ndarray): Binary mask where contours will be found.
    - min_area (int): Minimum area to be considered valid.

    Returns:
    - tuple: (x, y, w, h) bounding box of the largest valid contour, or None if none found.
    """
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    valid_contours = [c for c in contours if cv2.contourArea(c) >= min_area]
    if not valid_contours:
        return None
    largest_c = max(valid_contours, key=cv2.contourArea)
    return cv2.boundingRect(largest_c)

def preprocess_mask(binary_mask):
    """
    Smoothes small holes/gaps in the binary mask.

    Parameters:
    - binary_mask (np.ndarray): A binary mask of the object.

    Returns:
    - np.ndarray: Smoothed binary mask.
    """
    kernel = np.ones((5, 5), np.uint8)
    return cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)




def rotate_image(image, angle):
    """
    Rotates an image about its center by a given angle in degrees.

    Parameters:
    - image (np.ndarray): The input image or mask.
    - angle (float): Rotation angle in degrees.

    Returns:
    - np.ndarray: Rotated image or mask.
    """
    h, w = image.shape[:2]
    center = (w // 2, h // 2)
    rot_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)

    abs_cos = abs(rot_matrix[0, 0])
    abs_sin = abs(rot_matrix[0, 1])

    # Compute the new dimensions of the rotated image
    new_w = int(h * abs_sin + w * abs_cos)
    new_h = int(h * abs_cos + w * abs_sin)
    
    # Adjust the rotation matrix to account for translation (no cropping)
    rot_matrix[0, 2] += (new_w / 2) - center[0]
    rot_matrix[1, 2] += (new_h / 2) - center[1]
    
    # Perform the rotation with the new dimensions
    rotated_image = cv2.warpAffine(image, rot_matrix, (new_w, new_h))
    return rotated_image


def isolate_adjacent_fat(muscle_mask, fat_mask, debug_messages, dilation_size=15, min_area=500):
    """
    Extracts only the portion of fat that lies adjacent (within 'dilation_size' pixels) to the muscle.

    Steps:
    1. Dilate the muscle mask to form a band around the muscle.
    2. Intersect this band with the fat mask -> 'adjacent_fat'.
    3. Morphologically close the result to remove small holes.
    4. Keep the largest contour (above min_area).

    Parameters:
    - muscle_mask (np.ndarray): Binary mask of the muscle.
    - fat_mask (np.ndarray): Binary mask of the fat.
    - dilation_size (int): Pixel size for dilation to define adjacency.
    - min_area (int): Minimum area for a valid fat region.

    Returns:
    - tuple: (x, y, w, h) bounding box of the adjacent fat region, or None if none found.
    """
    debug_messages.append(f"dilation size: {dilation_size}, minimum valid area: {min_area}")
    # 1. Dilate the muscle mask
    dilated_muscle = dilate_mask(muscle_mask, kernel_size=dilation_size)

    # 2. Intersection with the fat mask
    adjacent_fat = cv2.bitwise_and(dilated_muscle, fat_mask)

    # 3. Smooth the adjacent fat region
    adjacent_fat = preprocess_mask(adjacent_fat)
    # 4. Find largest valid contour
    return find_largest_contour(adjacent_fat, min_area=min_area), debug_messages